import { useEffect } from 'react';

import { Mic } from 'lucide-react';
import { useNavigate } from 'react-router-dom';
import SpeechRecognition, {
  useSpeechRecognition,
} from 'react-speech-recognition';

import { TodayWriteStore } from '@/store/todayWriteStore';

import VoiceInput from './components/VoiceInput';

const VoiceToTextPage = () => {
  const navigate = useNavigate();
  const { transcript, listening, resetTranscript } = useSpeechRecognition();

  // ì¶”ê°€: ë²„íŠ¼ í´ë¦­ í•œ ë²ˆìœ¼ë¡œ ê¶Œí•œ ìš”ì²­ + ìŒì„± ì¸ì‹ ì‹œì‘
  const handleStart = async () => {
    try {
      console.log(
        'ğŸ§ª ë¸Œë¼ìš°ì € ì§€ì› ì—¬ë¶€:',
        SpeechRecognition.browserSupportsSpeechRecognition(),
      );
      console.log('ğŸ” í˜„ì¬ í”„ë¡œí† ì½œ:', window.location.protocol);

      // 1) ì‚¬ìš©ì ì œìŠ¤ì²˜ ë‚´ì—ì„œ ê¶Œí•œ ìš”ì²­ (íŒì—…)
      await navigator.mediaDevices.getUserMedia({ audio: true });
      console.log('âœ… ë§ˆì´í¬ ê¶Œí•œ í—ˆìš©ë¨');

      // 2) ê¶Œí•œ í—ˆìš© í›„ ìŒì„± ì¸ì‹ ì‹œì‘
      console.log('ğŸ™ ìŒì„± ì¸ì‹ ì‹œì‘ ì‹œë„');
      SpeechRecognition.startListening({
        continuous: false, // í•œ ë²ˆë§Œ ë“£ê³  ìë™ ì¢…ë£Œ
        interimResults: true, // ì¤‘ê°„ ê²°ê³¼ ì¦‰ì‹œ ë°˜í™˜
        language: 'ko',
      });
      console.log('ğŸ™ ìŒì„± ì¸ì‹ ì‹œì‘ë¨');
    } catch (e: any) {
      console.error('ğŸš« ë§ˆì´í¬ ê¶Œí•œ ì‹¤íŒ¨:', e.name, e.message);
      alert('âš ï¸ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì•¼ ë…¹ìŒì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.');
    }
  };

  // ì»´í¬ë„ŒíŠ¸ ì²˜ìŒ ë Œë”ë§ ì‹œ ì‹¤í–‰
  useEffect(() => {
    resetTranscript();
    return () => {
      SpeechRecognition.stopListening();
    };
  }, []);

  // ë³€í™˜(ì¤‘ì§€) ë²„íŠ¼ í´ë¦­
  const handleConvert = async () => {
    try {
      await SpeechRecognition.abortListening();
      console.log('ğŸ™ ìŒì„± ì¸ì‹ ì™„ì „ ì¢…ë£Œë¨');
    } catch (err) {
      console.error('âŒ abortListening ì˜¤ë¥˜:', err);
    }
  };

  // ì·¨ì†Œ ë²„íŠ¼ í´ë¦­
  const handleCancle = () => {
    resetTranscript();
    SpeechRecognition.abortListening();
    console.log('ğŸ™ ìŒì„± ì¸ì‹ ì™„ì „ ì¢…ë£Œë¨');
    navigate('/todaywrite');
  };

  // ì €ì¥ ë²„íŠ¼ í´ë¦­ ì‹œ
  const handleSave = () => {
    if (transcript.trim()) {
      TodayWriteStore.getState().addTextBlock(transcript.trim());
    }
    SpeechRecognition.abortListening();
    console.log('ğŸ™ ìŒì„± ì¸ì‹ ì™„ì „ ì¢…ë£Œë¨');
    navigate('/todaywrite');
  };

  return (
    <div className='flex min-h-[calc(100vh-150px)] w-full flex-col items-center justify-center gap-6'>
      <div className='flex flex-col items-center justify-center'>
        <div className='relative mb-6'>
          <div className='h-20 w-20 animate-ping rounded-full bg-haru-beige opacity-75'></div>
          <div className='absolute inset-0 flex items-center justify-center'>
            <div className='flex h-14 w-14 items-center justify-center rounded-full bg-haru-beige'>
              <Mic className='h-6 w-6 text-white' />
            </div>
          </div>
        </div>

        <p className='mb-4 text-sm font-semibold text-gray-700'>
          {listening ? 'ë“£ê³  ìˆì–´ìš”!' : 'ë…¹ìŒì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤'}
        </p>

        <div className='flex gap-2'>
          {listening ? (
            // ë…¹ìŒ ì¤‘ì¼ ë• ì¤‘ì§€ ë²„íŠ¼ë§Œ
            <button
              onClick={handleConvert}
              className='px-3 py-2 text-xs font-semibold text-haru-green'
            >
              ì¤‘ì§€
            </button>
          ) : (
            // ìˆ˜ì •: listening=false ì‹œ handleStart ë²„íŠ¼ë§Œ í‘œì‹œ
            <button
              onClick={handleStart}
              className='bg-haru-blue rounded px-4 py-2 text-xs font-semibold text-haru-green'
            >
              ë…¹ìŒ ì‹œì‘
            </button>
          )}
        </div>
      </div>

      <VoiceInput
        text={transcript}
        onSave={handleSave}
        onCancle={handleCancle}
      />
    </div>
  );
};

export default VoiceToTextPage;
