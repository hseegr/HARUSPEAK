import { useEffect } from 'react';

import { Mic } from 'lucide-react';
import { useNavigate } from 'react-router-dom';
import SpeechRecognition, {
  useSpeechRecognition,
} from 'react-speech-recognition';

import { TodayWriteStore } from '@/store/todayWriteStore';

import VoiceInput from './components/VoiceInput';

const VoiceToTextPage = () => {
  const navigate = useNavigate();
  const { transcript, listening, resetTranscript } = useSpeechRecognition();

  // âœ¨ì¶”ê°€: ë²„íŠ¼ í´ë¦­ í•œ ë²ˆìœ¼ë¡œ ê¶Œí•œ ìš”ì²­ + ìŒì„± ì¸ì‹ ì‹œì‘
  const handleStart = async () => {
    try {
      // 1) ì‚¬ìš©ì ì œìŠ¤ì²˜ ë‚´ì—ì„œ ê¶Œí•œ ìš”ì²­ (íŒì—…)
      await navigator.mediaDevices.getUserMedia({ audio: true });
      // 2) ê¶Œí•œ í—ˆìš© í›„ ìŒì„± ì¸ì‹ ì‹œì‘
      SpeechRecognition.startListening({ continuous: true, language: 'ko' });
    } catch (e: any) {
      console.error('ğŸš« ë§ˆì´í¬ ê¶Œí•œ ì‹¤íŒ¨:', e.name, e.message);
      alert('âš ï¸ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì•¼ ë…¹ìŒì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.');
    }
  };

  // ì»´í¬ë„ŒíŠ¸ ì²˜ìŒ ë Œë”ë§ ì‹œ ì‹¤í–‰
  useEffect(() => {
    resetTranscript();

    // âœ¨ì‚­ì œ ë˜ëŠ” ì£¼ì„ ì²˜ë¦¬ ê°€ëŠ¥: ìë™ ì¬ìš”ì²­ ë¡œì§
    const retryTimeout = setTimeout(() => {
      navigator.mediaDevices
        .getUserMedia({ audio: true })
        .then(() => {
          SpeechRecognition.startListening({
            continuous: true,
            language: 'ko',
          });
          console.log('ê¶Œí•œ ì¬í—ˆìš© í›„ ë‹¤ì‹œ ì¸ì‹ ì‹œì‘');
        })
        .catch(e => {
          console.error('ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ì‹¤íŒ¨:', e.name, e.message);
        });
    }, 300);

    return () => {
      clearTimeout(retryTimeout);
      SpeechRecognition.stopListening();
    };
  }, []);

  // ë³€í™˜(ì¤‘ì§€) ë²„íŠ¼ í´ë¦­
  const handleConvert = () => {
    SpeechRecognition.stopListening();
  };

  // ì·¨ì†Œ ë²„íŠ¼ í´ë¦­
  const handleCancle = () => {
    resetTranscript();
    navigate('/todaywrite');
  };

  // âœ¨ì‚­ì œ ë˜ëŠ” ë¹„í™œì„±í™” ê°€ëŠ¥: ì´ì–´ì„œ/ì¬ë…¹ìŒ ë¡œì§ì€ ì´ì œ handleStartë¡œ í†µí•©
  // const handleContinue = () => {
  //   SpeechRecognition.startListening({ continuous: true, language: 'ko' });
  // };
  // const handleReRecord = () => {
  //   resetTranscript();
  //   SpeechRecognition.startListening({ continuous: true, language: 'ko' });
  // };

  // ì €ì¥ ë²„íŠ¼ í´ë¦­ ì‹œ
  const handleSave = () => {
    if (transcript.trim()) {
      TodayWriteStore.getState().addTextBlock(transcript.trim());
    }
    navigate('/todaywrite');
  };

  return (
    <div className='flex min-h-[calc(100vh-150px)] w-full flex-col items-center justify-center gap-6'>
      <div className='flex flex-col items-center justify-center'>
        <div className='relative mb-6'>
          <div className='h-20 w-20 animate-ping rounded-full bg-haru-beige opacity-75'></div>
          <div className='absolute inset-0 flex items-center justify-center'>
            <div className='flex h-14 w-14 items-center justify-center rounded-full bg-haru-beige'>
              <Mic className='h-6 w-6 text-white' />
            </div>
          </div>
        </div>

        <p className='mb-4 text-sm font-semibold text-gray-700'>
          {listening ? 'ë“£ê³  ìˆì–´ìš”!' : 'ë…¹ìŒì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤'}
        </p>

        <div className='flex gap-2'>
          {listening ? (
            // ë…¹ìŒ ì¤‘ì¼ ë• ì¤‘ì§€ ë²„íŠ¼ë§Œ
            <button
              onClick={handleConvert}
              className='px-3 py-2 text-xs font-semibold text-haru-green'
            >
              ì¤‘ì§€
            </button>
          ) : (
            // âœ¨ìˆ˜ì •: listening=false ì‹œ â–¶ï¸ handleStart ë²„íŠ¼ë§Œ í‘œì‹œ
            <button
              onClick={handleStart}
              className='bg-haru-blue rounded px-4 py-2 text-xs font-semibold text-haru-green'
            >
              ë…¹ìŒ ì‹œì‘
            </button>
          )}
        </div>
      </div>

      <VoiceInput
        text={transcript}
        onSave={handleSave}
        onCancle={handleCancle}
      />
    </div>
  );
};

export default VoiceToTextPage;
